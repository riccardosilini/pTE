{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcTxcZz5Er25",
    "colab_type": "text"
   },
   "source": [
    "# pseudo transfer entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEfYXiHAEq4P",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Copyright (c) 2020 Riccardo Silini\n",
    "# Adapted and modified from a MATLAB routine written by M. Chavez\n",
    "# Please acknowledge and cite the use of this software and its authors\n",
    "# when results are used in publications or published elsewhere.\n",
    "\n",
    "\"\"\"Functions to compute pseudo transfer entropy (pTE).\n",
    "\n",
    "This module provides a set of functions to compute pTE between different\n",
    "time series.\n",
    "\n",
    "Functions\n",
    "---------------------\n",
    "\n",
    "  * normalisa -- L2 normalization, can be replaced by the \n",
    "    sklearn.preprocessing.normalize(*args) function\n",
    "  * embed -- generates matrices containing segments of the original time\n",
    "    series, depending on the embedding size chosen.\n",
    "  * timeshifted -- creeates time shifted surrogates. The sign on the shift means\n",
    "    that the time series that must be shifted is the independent one\n",
    "  * pTE -- Computes the pseudo transfer entropy between time series.\n",
    "\n",
    "Libraries required\n",
    "---------------------\n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "from collections import deque\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def normalisa(a, order=2, axis=-1):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "def embed(x, embd, lag):\n",
    "    N = len(x)\n",
    "    hidx = np.arange(embd * lag, step=lag)\n",
    "    vidx = np.arange(N - (embd - 1) * lag)\n",
    "    vidx = vidx.T\n",
    "    Nv = len(vidx)\n",
    "    U = np.array([x, ] * embd)\n",
    "    W = np.array([hidx, ] * Nv).T + np.array([vidx, ] * embd)\n",
    "    u = np.zeros((embd, Nv))\n",
    "    for i in range(embd):\n",
    "        for j in range(Nv):\n",
    "            u[i, j] = U[i, W[i, j]]\n",
    "    return u.T\n",
    "\n",
    "\n",
    "def timeshifted(timeseries, shift):\n",
    "    ts = deque(timeseries)      \n",
    "    ts.rotate(shift)\n",
    "    return np.asarray(ts)   \n",
    "\n",
    "\n",
    "def pTE(z, tau=1, dimEmb=1):\n",
    "    \n",
    "    \"\"\"Returns pseudo transfer entropy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array\n",
    "        array of arrays, containing all the time series.\n",
    "    tau : integer\n",
    "        delay of the embedding.  \n",
    "    dimEMb : integer\n",
    "        embedding dimension, or model order.       \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pte : array\n",
    "        array of arrays. The dimension is (# time series, # time series). \n",
    "        The diagonal is 0, while the off diagonal term (i, j) corresponds\n",
    "        to the pseudo transfer entropy from time series i to time series j.\n",
    "    \"\"\"\n",
    "\n",
    "    NN, T = np.shape(z)\n",
    "    Npairs = NN * (NN - 1)\n",
    "    pte = np.zeros((NN, NN))\n",
    "    z = normalisa(sps.detrend(z))\n",
    "    channels = np.arange(NN, step=1)\n",
    "\n",
    "    for i in channels:\n",
    "        EmbdDumm = embed(z[i], dimEmb + 1, tau)\n",
    "        Xtau = EmbdDumm[:, :-1]\n",
    "        for j in channels:\n",
    "            if i != j:\n",
    "                Yembd = embed(z[j], dimEmb + 1, tau)\n",
    "                Y = Yembd[:, -1]\n",
    "                Ytau = Yembd[:, :-1]\n",
    "                XtYt = np.concatenate((Xtau, Ytau), axis=1)\n",
    "                YYt = np.concatenate((Y[:, np.newaxis], Ytau), axis=1)\n",
    "                YYtXt = np.concatenate((YYt, Xtau), axis=1)\n",
    "\n",
    "                if dimEmb > 1:\n",
    "                    ptedum = np.linalg.det(np.cov(XtYt.T)) * np.linalg.det(np.cov(YYt.T)) / (\n",
    "                            np.linalg.det(np.cov(YYtXt.T)) * np.linalg.det(np.cov(Ytau.T)))\n",
    "                else:\n",
    "                    ptedum = np.linalg.det(np.cov(XtYt.T)) * np.linalg.det(np.cov(YYt.T)) / (\n",
    "                            np.linalg.det(np.cov(YYtXt.T)) * np.cov(Ytau.T))\n",
    " \n",
    "                pte[i, j] = 0.5 * np.log(ptedum)\n",
    "\n",
    "    TXY_ = pte            \n",
    "\n",
    "    \"\"\" WORK IN PROGRESS : the following part is use to deal with fake causalities arising from 3+ processes\n",
    "                           systems \"\"\"\n",
    "    \n",
    "    if np.sum(Fs) == 3 and np.linalg.det(Fs) == 0:\n",
    "\n",
    "        k = np.argwhere(np.sum(Fs, axis=1)==2)\n",
    "        j = np.argwhere(np.sum(Fs, axis=1)==1)\n",
    "        l = np.argwhere(np.sum(Fs, axis=1)==0)\n",
    "        if len(k)!=0 and len(j)!=0 and len(l)!=0:\n",
    "            for idx, i in enumerate(Fs):\n",
    "                indexes = np.where(i==1)[0]\n",
    "                if len(indexes) > 0:\n",
    "                    pairs = list(itertools.combinations(indexes, 2))\n",
    "                    for pair in pairs:\n",
    "                        indice1 = np.where(np.sum(Fs, axis = 1) == 2)[0]\n",
    "                        indice2 = np.where(np.sum(Fs, axis = 0) == 2)[0]\n",
    "                        if Fs[pair] == 1:\n",
    "                            TXY_temp = np.multiply(TXY, Fs)\n",
    "                            exponent = TXY_temp[k,l]/TXY_temp[j,l] - 1\n",
    "                            if np.abs(exponent)>0.5:\n",
    "                                ratio = (TXY_temp[pair[0], idx]/TXY_temp[idx, pair[0]])**(2*np.sign(exponent))\n",
    "                                if ratio<1:\n",
    "                                    TXY_[pair] = TXY[pair] * ratio\n",
    "                                if ratio >= 1:\n",
    "                                    ratio2 = (TXY_temp[indice1, pair[0]]/TXY_temp[pair[0], indice1])**(2*np.sign(exponent))\n",
    "                                    if ratio2<1:    \n",
    "                                        TXY_[indice1, indice2] = TXY[indice1, indice2] * ratio2\n",
    "                        if Fs[pair[::-1]] == 1:\n",
    "                            TXY_temp = np.multiply(TXY, Fs)\n",
    "                            exponent = TXY_temp[k,l]/TXY_temp[j,l] - 1\n",
    "                            if np.abs(exponent)>0.5:\n",
    "                                ratio = (TXY_temp[pair[1], idx]/TXY_temp[idx, pair[1]])**(2*np.sign(exponent))\n",
    "                                if ratio<1:\n",
    "                                    TXY_[pair[::-1]] = TXY[pair[::-1]] * ratio\n",
    "                                if ratio >= 1:  \n",
    "                                    ratio2 = (TXY[indice1, pair[1]]/TXY[pair[1], indice1])**(2*np.sign(exponent))\n",
    "                                    if ratio2<1:\n",
    "                                        TXY_[indice2, indice1] = TXY[indice2, indice1] * ratio2\n",
    "    pte = TXY_                     \n",
    "    return pte\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pTE.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyP1q6lDcDeKIrks5vOgJ2Ij"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
